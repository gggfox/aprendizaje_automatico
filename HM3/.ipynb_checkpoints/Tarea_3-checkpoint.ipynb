{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "lesbian-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Lucía Cantú-Miller  \t\t     A01194199\n",
    "#  Jesus Lozano  \t\t \t     A01194162\n",
    "#  Adrián Hinojosa  \t\t\t A00822490\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from LogisticRegressor import LogisticRegressor\n",
    "#remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "indoor-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sigmoid function.\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "pressing-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z function that will help print out every iteration's theta.\n",
    "def z(input, Theta):\n",
    "    # print('Theta is {} in transpose {}, input is {}'.format(Theta.shape, Theta.T.shape, input.shape))\n",
    "    # we need to get an n x m array, where n is the neurons in this layer and m is the number of activations we used\n",
    "    return Theta @ input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "impaired-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an activation function which works by calling the sigmoid function.\n",
    "def activation(z):\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "broadband-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights to start our model. \n",
    "def initialize_weights(X, num_classes, hidden):\n",
    "    weights = []\n",
    "    out_neurons = num_classes # len(y)\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    h_layers = len(hidden)\n",
    "    # print('Hidden layers will be {}'.format(h_layers))\n",
    "    s_j = n\n",
    "    # [2]\n",
    "    for j in range(0,h_layers):\n",
    "        s_jplus1 = hidden[j]\n",
    "        cols = s_j + 1\n",
    "        # print('Theta {} will be {}x{}'.format(j+1, s_jplus1, cols))\n",
    "        # weights_layer = np.zeros((s_jplus1, cols))\n",
    "        weights_layer = np.random.rand(s_jplus1, cols)\n",
    "        weights.append(weights_layer)\n",
    "        s_j = s_jplus1\n",
    "    \n",
    "    # weights.append(np.zeros((out_neurons, s_j + 1)))\n",
    "    weights.append(np.random.rand(out_neurons, s_j + 1))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "smart-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the activations for the output neurons.\n",
    "def initialize_activations(X, output_neurons, hidden):\n",
    "    # initialize activations, they are\n",
    "    # input layer: (n+1) x 1, \n",
    "    # hidden: (each + 1) x 1\n",
    "    # output: output_neurons x 1\n",
    "    # So we can represent them with a list of length 2 + len(hidden)\n",
    "\n",
    "    activations = []\n",
    "    # input layer\n",
    "    a_1 = np.array([X[:,0]]).T\n",
    "    biases = np.ones(a_1.shape[1])\n",
    "    a_1 = np.vstack((biases, a_1))\n",
    "    activations.append(a_1)\n",
    "\n",
    "    for i in range(len(hidden)):\n",
    "        a_i = np.zeros((hidden[i] + 1 , 1))\n",
    "        a_i[0,0] = 1.0\n",
    "        activations.append(a_i)\n",
    "\n",
    "    # output layer\n",
    "    activations.append(np.zeros((output_neurons,1)))\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "early-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward function in order to feed forward.\n",
    "def forward(X, hidden, activations, weights):\n",
    "    m = X.shape[1]\n",
    "    for e in range(m):\n",
    "        # a^0 = X\n",
    "        # print('activations shape {} '.format(activations.shape))\n",
    "        # print('initial activations {}'.format(activations))\n",
    "        \n",
    "        # FeedForward\n",
    "        # Hidden layers\n",
    "        for i in range(0, len(hidden)):\n",
    "            a_i = activations[i]\n",
    "            # print('In Layer {}'.format(i+1))\n",
    "            z_next = z(a_i, theta[i])\n",
    "            # print('z_i are {}'.format(z_next.T))\n",
    "            a_next = activation(z_next)\n",
    "            activations[i+1][1:] = a_next # this line would fail for output layer\n",
    "            # print('activations {} are {}'.format(i+1, a_next))\n",
    "\n",
    "        # output layer (i+2 is the output layer)\n",
    "        a_i = activations[i+1]\n",
    "        z_next = z(a_i, theta[i+1])\n",
    "        a_next = activation(z_next)\n",
    "        activations[i+2] = a_next\n",
    "        # print('output is {}'.format(a_next.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "promotional-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses the backpropagation algorithm, using the solution context.\n",
    "def backprop(y, hidden, activations, theta, alpha, reg):\n",
    "    m = len(y)\n",
    "    delta = []\n",
    "    # Calculating local gradients\n",
    "    # Output layer\n",
    "    y_pred = activations[-1]\n",
    "    delta_i = y_pred - y\n",
    "    # print('Error is {}'.format(delta_i.T))\n",
    "    delta.append(delta_i)\n",
    "\n",
    "    start = len(activations) - 1\n",
    "\n",
    "    # Hidden layers\n",
    "    for i in range(start, 1, -1): # we don't calculate errors for input layer\n",
    "        # print('In layer {}'.format(i))\n",
    "        theta_prev = theta[i-1][:,1:] # this is ignoring bias\n",
    "        tmp = theta_prev.T @ delta_i\n",
    "        # print('tmp is {}'.format(tmp.T))\n",
    "        delta_i = tmp * ( activations[i-1][1:] * (1 - activations[i-1][1:])) # this is ignoring bias\n",
    "        # print('Error is {}'.format(delta_i.T))\n",
    "        delta.append(delta_i)\n",
    "    \n",
    "    # delta list holds the values\n",
    "    # delta length is all but first layer (layers-1)\n",
    "    # we could add an extra column for input layer to have the same\n",
    "    # indexes as in the slides\n",
    "    delta.reverse()\n",
    "    # print(delta)\n",
    "\n",
    "    # Calculating Deltas\n",
    "    num_clases = theta[-1].shape[0]\n",
    "    Delta = initialize_weights(X, num_clases, hidden) # The Delta has the same dimensions as the weight matrix (we will ignore bias though)\n",
    "    # This is for weights, not for neurons, that is why we reach layer 1\n",
    "    start = len(delta) - 1\n",
    "    for i in range(start, -1, -1):\n",
    "        # print('Now in layer {}'.format(i+1))\n",
    "        activations_this_layer = activations[i][1:,:] # this is ignoring bias\n",
    "        delta_next_layer = delta[i]\n",
    "        activations_times_delta = activations_this_layer@delta_next_layer.T\n",
    "        Delta[i][:,1:] = activations_times_delta.T \n",
    "    \n",
    "    D = [ x/m for x in Delta]\n",
    "\n",
    "    for i in range(len(D)):\n",
    "        d = D[i]\n",
    "        t = theta[i]\n",
    "        d[:,1:] += reg * t[:,1:]\n",
    "    \n",
    "    for i in range(len(theta)):\n",
    "        t = theta[i]\n",
    "        d = D[i]\n",
    "\n",
    "        t[:, 1:] = t[:, 1:] - (alpha * d[:, 1:])\n",
    "\n",
    "    # print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ethical-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    a_i = X\n",
    "    # all theta layers\n",
    "    for i in range(len(theta)):\n",
    "        # print('In layer {}'.format(i+1))\n",
    "        biases = np.ones(a_i.shape[1])\n",
    "        a_i = np.vstack((biases, a_i))\n",
    "\n",
    "        z_next = z(a_i, theta[i])\n",
    "        a_i = activation(z_next)\n",
    "\n",
    "    return a_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "qualified-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cosmetic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "from numpy import meshgrid\n",
    "from numpy import arange\n",
    "from numpy import hstack\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "def plot_decision_boundary(X, y, classifier):\n",
    "    # for other color maps, see\n",
    "    # https://matplotlib.org/stable/gallery/color/colormap_reference.html\n",
    "    colormap = 'Greens'\n",
    "    # unique classes:\n",
    "    unique_classes = np.unique(y)\n",
    "    # define bounds of the domain\n",
    "    # min1, max1 = X[:, 0].min()-1, X[:, 0].max()+1\n",
    "    # min2, max2 = X[:, 1].min()-1, X[:, 1].max()+1\n",
    "    # again, this is because in 0 we have the bias\n",
    "    min1, max1 = X[:, 1].min()-1, X[:, 1].max()+1\n",
    "    min2, max2 = X[:, 2].min()-1, X[:, 2].max()+1\n",
    "    # define the x and y scale\n",
    "    x1grid = arange(min1, max1, 0.1)\n",
    "    x2grid = arange(min2, max2, 0.1)\n",
    "    # create all of the columns and rows of the grid\n",
    "    xx, yy = meshgrid(x1grid, x2grid)\n",
    "    # flatten each grid to a vector\n",
    "    r1, r2 = xx.flatten(), yy.flatten()\n",
    "    r1, r2 = r1.reshape((len(r1), 1)), r2.reshape((len(r2), 1)) # to obtain an Lx1 vector rather than (L,) vector\n",
    "    # horizontal stack vectors to create x1,x2 input for the model\n",
    "    grid = hstack((r1,r2))\n",
    "\n",
    "    # TODO: Your classifier goes here\n",
    "    # make predictions for the grid\n",
    "    the_ones = np.ones((grid.shape[0],1))\n",
    "    yhat = classifier.predict(np.column_stack((the_ones,grid)).T) \n",
    "    # reshape the predictions back into a grid\n",
    "    zz = yhat.reshape(xx.shape)\n",
    "\n",
    "    pyplot.figure()\n",
    "    # plot the grid of x, y and z values as a surface\n",
    "    pyplot.contourf(xx, yy, zz, cmap=colormap)\n",
    "\n",
    "    # create scatter plot for samples from each class\n",
    "    # for class_value in range(len(unique_classes)):\n",
    "    for class_value in unique_classes:\n",
    "        # get row indexes for samples with this class\n",
    "        row_ix = where(y == class_value)[0] # need the first element of the tuple :S\n",
    "        # create scatter of these samples\n",
    "        # pyplot.scatter(X[row_ix, 0], X[row_ix, 1], alpha=0.5, cmap=colormap)\n",
    "        # This is because 0 is the bias, always 1\n",
    "        pyplot.scatter(X[row_ix, 1], X[row_ix, 2], alpha=0.5, cmap=colormap)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "civil-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final theta is [[ 0.370717    1.16857673 -4.1465483 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.95437187 -0.46553674]] pred as [[0.5182517  0.50331791]], should be [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# main function which will read the data from the blobs.csv and call the other functions for using an artificial neural network.\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data = pd.read_csv('moons.csv')\n",
    "    X = data.iloc[:,:-1].to_numpy().T # all but last column of labels\n",
    "    the_ones = np.ones((X.shape[1],1)).T # (1xm) additional row of 1's\n",
    "    X = np.row_stack((the_ones, X)) # adding the row of 1's\n",
    "    y = data.iloc[:,-1].to_numpy() # the last col is class\n",
    "    Y = y.reshape(y.shape[0],-1).T # this is to get (1,m) rather than an (m,) array (2d instead of 1d)\n",
    "    \n",
    "    lr = LogisticRegressor(alpha=0.001, epochs=100000)\n",
    "    lr.fit(X,Y) \n",
    "    \n",
    "    plot_decision_boundary(X.T, y.T, lr)\n",
    "    plt.show()\n",
    "\n",
    "    y = y.reshape(-1,1)  # to get an mx1 array and not (m,)\n",
    "    unique_classes = len(np.unique(y))\n",
    "    y = get_one_hot(y, unique_classes)\n",
    "    \n",
    "    hidden = [2,5]\n",
    "    theta = initialize_weights(X, unique_classes, hidden)\n",
    "    activations = initialize_activations(X,unique_classes,hidden)\n",
    "\n",
    "    m = X.shape[1]\n",
    "    epochs = 2000\n",
    "    for e in range(epochs):\n",
    "        # print('Epoch {} '.format(e))\n",
    "        for i in range(m):\n",
    "            X_i = X[:,i]\n",
    "            X_i = X_i.reshape(-1,1)\n",
    "            y_i = y[i, :].T\n",
    "            forward(X_i, hidden, activations, theta)\n",
    "            backprop(y_i, hidden, activations, theta, alpha=0.5, reg=0)\n",
    "    \n",
    "    to_pred = X[:,0]\n",
    "    y_i = y[0, :].T\n",
    "    to_pred = to_pred.reshape(-1,1)\n",
    "    y_pred = predict(to_pred, theta)\n",
    "    print('{} pred as {}, should be {}'.format(to_pred.T, y_pred.T, y_i.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-worthy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
